---
title: 'Challenging the Abilities of Large Language Models in Italian: a Community
  Initiative'

# Authors
# A YAML list of author names
# If you created a profile for a user (e.g. the default `admin` user at `content/authors/admin/`), 
# write the username (folder name) here, and it will be replaced with their full name and linked to their profile.
authors:
- Malvina Nissim
- Danilo Croce
- Viviana Patti
- Pierpaolo Basile
- Giuseppe Attanasio
- Elio Musacchio
- Matteo Rinaldi
- Federico Borazio
- Maria Francis
- Jacopo Gili
- ' others'

# Author notes (such as 'Equal Contribution')
# A YAML list of notes for each author in the above `authors` list
author_notes: []

date: '2025-12-04'

# Date to publish webpage (NOT necessarily Bibtex publication's date).
publishDate: ''

# Publication type.
# A single CSL publication type but formatted as a YAML list (for Hugo requirements).
publication_types:
- article-journal

# Publication name and optional abbreviated publication name.
publication: '*arXiv*'
publication_short: ''

doi: ''

abstract: 'The rapid progress of Large Language Models (LLMs) has transformed natural
  language processing and broadened its impact across research and society. Yet, systematic
  evaluation of these models, especially for languages beyond English, remains limited.
  \"Challenging the Abilities of LAnguage Models in ITAlian\" (CALAMITA) is a large-scale
  collaborative benchmarking initiative for Italian, coordinated under the Italian
  Association for Computational Linguistics. Unlike existing efforts that focus on
  leaderboards, CALAMITA foregrounds methodology: it federates more than 80 contributors
  from academia, industry, and the public sector to design, document, and evaluate
  a diverse collection of tasks, covering linguistic competence, commonsense reasoning,
  factual consistency, fairness, summarization, translation, and code generation.
  Through this process, we not only assembled a benchmark of over 20 tasks and almost
  100 subtasks, but also established a centralized evaluation pipeline that supports
  heterogeneous datasets and metrics. We report results for four open-weight LLMs,
  highlighting systematic strengths and weaknesses across abilities, as well as challenges
  in task-specific evaluation. Beyond quantitative results, CALAMITA exposes methodological
  lessons: the necessity of fine-grained, task-representative metrics, the importance
  of harmonized pipelines, and the benefits and limitations of broad community engagement.
  CALAMITA is conceived as a rolling benchmark, enabling continuous integration of
  new tasks and models. This makes it both a resource -- the most comprehensive and
  diverse benchmark for Italian to date -- and a framework for sustainable, community-driven
  evaluation. We argue that this combination offers a blueprint for other languages
  and communities seeking inclusive and rigorous LLM evaluation practices.'

# Summary. An optional shortened abstract.
summary: ''

tags:
- Natural Language Processing
- Large Language Models
- Deep Learning
- Evaluation
- Commonsense Reasoning
- Italian

# Display this page in a list of Featured pages?
featured: false

# Links
url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Custom links (uncomment lines below)
# links:
# - name: Custom Link
#   url: http://example.org

# Publication image
# Add an image named `featured.jpg/png` to your page's folder then add a caption below.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects: ['internal-project']` links to `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []
links:
- name: arXiv
  url: https://arxiv.org/abs/2512.04759
- type: pdf
  url: https://arxiv.org/pdf/2512.04759.pdf
- type: code
  url: https://github.com/CALAMITA-AILC/calamita-eval
---


